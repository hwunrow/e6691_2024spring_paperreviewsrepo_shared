# Attention Fundamentals

## References

- [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)
- [Effective approaches to attention-based neural machine translation](https://arxiv.org/abs/1508.04025)
- [Attention Mechanisms in Neural Networks - Where it comes and where it goes](https://arxiv.org/abs/2204.13154)
- [Attention Mechanisms](https://paperswithcode.com/methods/category/attention-mechanisms-1)
- [X-Former: In-Memory Acceleration of Transformers](https://ieeexplore.ieee.org/abstract/document/10155455)

## TODO student contributors

## TODO add content
